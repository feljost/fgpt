{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f8a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import pandas as pd\n",
    "\n",
    "# Load the contents\n",
    "with open(\"../../logs/train_metrics_20251220_1602.jsonl\", \"r\") as f:\n",
    "    train_metrics = [json.loads(line) for line in f]\n",
    "\n",
    "df_metrics = pd.DataFrame(train_metrics)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics[\"timestamp\"] = pd.to_datetime(df_metrics[\"timestamp\"], format=\"mixed\")\n",
    "\n",
    "# adjust timestamps after a slight hickup in training.\n",
    "cutoff = pd.Timestamp(\"2025-12-24T09:46:05\")\n",
    "mask = df_metrics[\"timestamp\"] < cutoff\n",
    "df_metrics.loc[mask, \"timestamp\"] += pd.Timedelta(hours=13, minutes=37)\n",
    "\n",
    "\n",
    "df_metrics[\"elapsed_hours\"] = (\n",
    "    df_metrics[\"timestamp\"] - df_metrics[\"timestamp\"].iloc[0]\n",
    ").dt.total_seconds() / 3600\n",
    "\n",
    "\n",
    "df_metrics[\"tokens_seen\"] = df_metrics[\"step\"] * 84 * 1024\n",
    "df_metrics[\"tokens_seen_b\"] = (df_metrics[\"step\"] * 84 * 1024 ) / 1e9  # in billions\n",
    "\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47df6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loss Figure\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(10, 5), facecolor=\"white\")\n",
    "ax1.plot(\n",
    "    df_metrics[\"step\"],\n",
    "    df_metrics[\"train_loss\"],\n",
    "    color=\"tab:blue\",\n",
    "    alpha=0.7,\n",
    "    label=\"Train Loss\",\n",
    ")\n",
    "\n",
    "ax1.plot(\n",
    "    df_metrics[\"step\"][df_metrics[\"val_loss\"].notna()],\n",
    "    df_metrics[\"val_loss\"][df_metrics[\"val_loss\"].notna()],\n",
    "    color=\"tab:orange\",\n",
    "    label=\"Validation Loss\",\n",
    "    zorder=4,\n",
    "    linewidth=3,\n",
    ")\n",
    "\n",
    "# Add horizontal lines for previous and target val loss\n",
    "ax1.axhline(2.8, color=\"tab:purple\", linestyle=\"--\", linewidth=2, label=\"Prev val loss\")\n",
    "ax1.axhline(2.7, color=\"tab:green\", linestyle=\":\", linewidth=2, label=\"Target val loss\")\n",
    "\n",
    "\n",
    "ax1.legend()\n",
    "ax1.yaxis.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "ax1.xaxis.set_major_locator(mticker.AutoLocator())\n",
    "ax1.xaxis.set_minor_locator(mticker.AutoMinorLocator())\n",
    "ax1.xaxis.grid(True, which=\"both\", linestyle=\":\", linewidth=0.5)\n",
    "# ax1.set_yscale(\"log\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_title(\"Cross Entropy Loss by Step (nats)\")\n",
    "ax1.grid(True)\n",
    "ax1.set_ylim(bottom=1.5, top=4.5)\n",
    "ax1.set_xlim(left=0, right=350000)\n",
    "fig1.patch.set_facecolor(\"white\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Learning Rate Figure\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 5))\n",
    "# ax2.plot(df_metrics[\"step\"], df_metrics[\"adamw_lr\"], color=\"tab:green\")\n",
    "ax2.plot(df_metrics[\"step\"], df_metrics[\"muon_lr\"], color=\"tab:blue\")\n",
    "ax2.set_xlabel(\"Step\")\n",
    "ax2.set_ylabel(\"Learning Rate\")\n",
    "ax2.set_title(\"Learning Rate by Step\")\n",
    "ax2.set_xlim(left=0, right=350000)\n",
    "ax2.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Hellaswag Eval Accuracy Figure\n",
    "fig3, ax3 = plt.subplots(figsize=(10, 5))\n",
    "ax3.plot(\n",
    "    df_metrics[\"tokens_seen\"][df_metrics[\"hellaswag_acc\"].notna()],\n",
    "    df_metrics[\"hellaswag_acc\"][df_metrics[\"hellaswag_acc\"].notna()],\n",
    "    color=\"tab:blue\",\n",
    "    marker=\"o\",\n",
    ")\n",
    "ax3.set_ylabel(\"Accuracy\")\n",
    "ax3.set_title(\"Hellaswag Eval Accuracy\")\n",
    "ax3.grid(True)\n",
    "ax3.set_ylim(bottom=0.23, top=0.5)\n",
    "# ax3.set_xlim(left=0, right=350000)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9f5067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norm Figure\n",
    "fig_norm, ax_norm = plt.subplots(figsize=(10, 5))\n",
    "ax_norm.plot(df_metrics[\"step\"], df_metrics[\"norm\"], color=\"tab:purple\")\n",
    "ax_norm.set_xlabel(\"Step\")\n",
    "ax_norm.set_ylabel(\"Norm\")\n",
    "ax_norm.set_title(\"Gradient Norm by Step\")\n",
    "ax_norm.set_xlim(left=0, right=350000)\n",
    "ax_norm.set_ylim(bottom=0, top=3)\n",
    "ax_norm.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be712e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loss Figure by hours\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(10, 5), facecolor=\"white\")\n",
    "ax1.plot(\n",
    "    df_metrics[\"elapsed_hours\"],\n",
    "    df_metrics[\"train_loss\"],\n",
    "    color=\"tab:blue\",\n",
    "    alpha=0.7,\n",
    "    label=\"Train Loss\",\n",
    ")\n",
    "\n",
    "ax1.plot(\n",
    "    df_metrics[\"elapsed_hours\"][df_metrics[\"val_loss\"].notna()],\n",
    "    df_metrics[\"val_loss\"][df_metrics[\"val_loss\"].notna()],\n",
    "    color=\"tab:orange\",\n",
    "    label=\"Validation Loss\",\n",
    "    zorder=4,\n",
    "    linewidth=3,\n",
    ")\n",
    "\n",
    "# Add horizontal lines for previous and target val loss\n",
    "ax1.axhline(2.8, color=\"tab:purple\", linestyle=\"--\", linewidth=2, label=\"Prev val loss\")\n",
    "ax1.axhline(2.7, color=\"tab:green\", linestyle=\":\", linewidth=2, label=\"Target val loss\")\n",
    "# ax1.plot([20000, 125000], [3.63, 3.31], color=\"tab:red\", linestyle=\"--\", linewidth=2, label=\"Prev decline\", zorder=99)\n",
    "\n",
    "ax1.legend()\n",
    "ax1.yaxis.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "ax1.xaxis.set_major_locator(mticker.AutoLocator())\n",
    "ax1.xaxis.set_minor_locator(mticker.AutoMinorLocator())\n",
    "ax1.xaxis.grid(True, which=\"both\", linestyle=\":\", linewidth=0.5)\n",
    "# ax1.set_yscale(\"log\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_title(\"Cross Entropy Loss by Hours trained (nats)\")\n",
    "ax1.grid(True)\n",
    "ax1.set_ylim(bottom=1.5, top=4.5)\n",
    "ax1.set_xlim(left=0, right=70)\n",
    "fig1.patch.set_facecolor(\"white\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635644b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Create a figure with GridSpec to control height ratios\n",
    "fig = plt.figure(figsize=(10, 7), facecolor=\"white\")\n",
    "gs = GridSpec(3, 1, height_ratios=[2.5, 1, 1], hspace=0.18)  # loss taller, lr/norm shorter\n",
    "\n",
    "# --- Loss Plot ---\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "ax1.plot(\n",
    "    df_metrics[\"tokens_seen_b\"],\n",
    "    df_metrics[\"train_loss\"],\n",
    "    color=\"tab:blue\",\n",
    "    alpha=0.7,\n",
    "    label=\"Train Loss\",\n",
    ")\n",
    "ax1.plot(\n",
    "    df_metrics[\"tokens_seen_b\"][df_metrics[\"val_loss\"].notna()],\n",
    "    df_metrics[\"val_loss\"][df_metrics[\"val_loss\"].notna()],\n",
    "    color=\"tab:orange\",\n",
    "    label=\"Validation Loss\",\n",
    "    zorder=4,\n",
    "    linewidth=3,\n",
    ")\n",
    "ax1.legend()\n",
    "ax1.yaxis.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "ax1.xaxis.set_major_locator(mticker.AutoLocator())\n",
    "ax1.xaxis.set_minor_locator(mticker.AutoMinorLocator())\n",
    "ax1.xaxis.grid(True, which=\"both\", linestyle=\":\", linewidth=0.5)\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_ylim(bottom=2, top=4.5)\n",
    "ax1.grid(True)\n",
    "ax1.set_xlabel(\"\")\n",
    "ax1.tick_params(labelbottom=False)\n",
    "\n",
    "# --- Learning Rate Plot ---\n",
    "ax2 = fig.add_subplot(gs[1], sharex=ax1)\n",
    "ax2.plot(df_metrics[\"tokens_seen_b\"], df_metrics[\"muon_lr\"], color=\"tab:green\")\n",
    "ax2.set_ylabel(\"Learning Rate\")\n",
    "ax2.grid(True)\n",
    "ax2.set_xlabel(\"\")\n",
    "ax2.tick_params(labelbottom=False)\n",
    "\n",
    "# --- Norm Plot ---\n",
    "ax3 = fig.add_subplot(gs[2], sharex=ax1)\n",
    "ax3.plot(df_metrics[\"tokens_seen_b\"], df_metrics[\"norm\"], color=\"tab:purple\")\n",
    "ax3.set_xlabel(\"Tokens [Billion]\")\n",
    "ax3.set_ylabel(\"Norm\")\n",
    "ax3.grid(True)\n",
    "ax3.set_ylim(bottom=0, top=2.5)\n",
    "# Plot a line from x=0 to x=22 at y=1\n",
    "ax3.plot([0, 22], [1, 1], color=\"red\", linestyle=\"--\", linewidth=2, zorder=99)\n",
    "ax3.plot([22, 22.0000001], [1, 0.5], color=\"red\", linestyle=\"--\", linewidth=2, zorder=99)\n",
    "ax3.plot([22, 30], [0.5, 0.5], color=\"red\", linestyle=\"--\", label=\"Norm clipping\", linewidth=2, zorder=99)\n",
    "ax3.legend()\n",
    "\n",
    "\n",
    "fig.suptitle(\"Pretraining Progress Overview\", fontsize=12,y =0.92)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20be47d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the contents\n",
    "with open(\"../../logs/instruct_training_metrics.jsonl\", \"r\") as f:\n",
    "    train_instruct = [json.loads(line) for line in f]\n",
    "\n",
    "df_instruct = pd.DataFrame(train_instruct)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5), facecolor=\"white\")\n",
    "ax.plot(df_instruct[\"step\"], df_instruct[\"train_loss\"], label=\"Train Loss\", color=\"tab:blue\", alpha=0.7)\n",
    "ax.plot(df_instruct[\"step\"], df_instruct[\"val_loss\"], label=\"Validation Loss\", color=\"tab:orange\", linewidth=2)\n",
    "ax.set_xlabel(\"Step\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(\"Train and Validation Loss (Instruct Tuning)\")\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab29a02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
