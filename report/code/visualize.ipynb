{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f8a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import pandas as pd\n",
    "\n",
    "# Load the contents\n",
    "with open(\"../../logs/train_metrics_20251220_1343.jsonl\", \"r\") as f:\n",
    "    train_metrics = [json.loads(line) for line in f]\n",
    "\n",
    "df_metrics = pd.DataFrame(train_metrics)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics[\"timestamp\"] = pd.to_datetime(df_metrics[\"timestamp\"])\n",
    "\n",
    "# adjust timestamps after a slight hickup in training.\n",
    "cutoff = pd.Timestamp(\"2025-12-20T15:50:00\")\n",
    "mask = df_metrics[\"timestamp\"] < cutoff\n",
    "df_metrics.loc[mask, \"timestamp\"] += pd.Timedelta(minutes=24)\n",
    "\n",
    "\n",
    "df_metrics[\"elapsed_hours\"] = (df_metrics[\"timestamp\"] - df_metrics[\"timestamp\"].iloc[0]).dt.total_seconds() / 3600\n",
    "\n",
    "\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47df6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loss Figure\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(10, 5), facecolor=\"white\")\n",
    "ax1.plot(\n",
    "    df_metrics[\"step\"],\n",
    "    df_metrics[\"train_loss\"],\n",
    "    color=\"tab:blue\",\n",
    "    alpha=0.7,\n",
    "    label=\"Train Loss\",\n",
    ")\n",
    "\n",
    "ax1.plot(\n",
    "    df_metrics[\"step\"][df_metrics[\"val_loss\"].notna()],\n",
    "    df_metrics[\"val_loss\"][df_metrics[\"val_loss\"].notna()],\n",
    "    color=\"tab:orange\",\n",
    "    label=\"Validation Loss\",\n",
    "    zorder=4,\n",
    "    linewidth=3,\n",
    ")\n",
    "\n",
    "# Add horizontal lines for previous and target val loss\n",
    "ax1.axhline(2.8, color=\"tab:purple\", linestyle=\"--\", linewidth=2, label=\"Prev val loss\")\n",
    "ax1.axhline(2.6, color=\"tab:green\", linestyle=\":\", linewidth=2, label=\"Target val loss\")\n",
    "ax1.plot([20000, 125000], [3.63, 3.31], color=\"tab:red\", linestyle=\"--\", linewidth=2, label=\"Prev decline\", zorder=99)\n",
    "\n",
    "ax1.legend()\n",
    "ax1.yaxis.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "ax1.xaxis.set_major_locator(mticker.AutoLocator())\n",
    "ax1.xaxis.set_minor_locator(mticker.AutoMinorLocator())\n",
    "ax1.xaxis.grid(True, which=\"both\", linestyle=\":\", linewidth=0.5)\n",
    "# ax1.set_yscale(\"log\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_title(\"Cross Entropy Loss by Step (nats)\")\n",
    "ax1.grid(True)\n",
    "ax1.set_ylim(bottom=1.5, top=4.5)\n",
    "ax1.set_xlim(left=0, right=310000)\n",
    "fig1.patch.set_facecolor(\"white\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Learning Rate Figure\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 5))\n",
    "# ax2.plot(df_metrics[\"step\"], df_metrics[\"adamw_lr\"], color=\"tab:green\")\n",
    "ax2.plot(df_metrics[\"step\"], df_metrics[\"muon_lr\"], color=\"tab:blue\")\n",
    "ax2.set_xlabel(\"Step\")\n",
    "ax2.set_ylabel(\"Learning Rate\")\n",
    "ax2.set_title(\"Learning Rate by Step\")\n",
    "ax2.set_xlim(left=0, right=310000)\n",
    "ax2.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Hellaswag Eval Accuracy Figure\n",
    "fig3, ax3 = plt.subplots(figsize=(10, 5))\n",
    "ax3.plot(\n",
    "    df_metrics[\"step\"][df_metrics[\"hellaswag_acc\"].notna()],\n",
    "    df_metrics[\"hellaswag_acc\"][df_metrics[\"hellaswag_acc\"].notna()],\n",
    "    color=\"tab:blue\",\n",
    "    marker=\"o\",\n",
    ")\n",
    "ax3.set_ylabel(\"Hellaswag Accuracy\")\n",
    "ax3.set_title(\"Hellaswag Eval Accuracy by Step (Base Model)\")\n",
    "ax3.grid(True)\n",
    "ax3.set_ylim(bottom=0.23, top=0.4)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be712e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loss Figure by hours\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(10, 5), facecolor=\"white\")\n",
    "ax1.plot(\n",
    "    df_metrics[\"elapsed_hours\"],\n",
    "    df_metrics[\"train_loss\"],\n",
    "    color=\"tab:blue\",\n",
    "    alpha=0.7,\n",
    "    label=\"Train Loss\",\n",
    ")\n",
    "\n",
    "ax1.plot(\n",
    "    df_metrics[\"elapsed_hours\"][df_metrics[\"val_loss\"].notna()],\n",
    "    df_metrics[\"val_loss\"][df_metrics[\"val_loss\"].notna()],\n",
    "    color=\"tab:orange\",\n",
    "    label=\"Validation Loss\",\n",
    "    zorder=4,\n",
    "    linewidth=3,\n",
    ")\n",
    "\n",
    "# Add horizontal lines for previous and target val loss\n",
    "ax1.axhline(2.8, color=\"tab:purple\", linestyle=\"--\", linewidth=2, label=\"Prev val loss\")\n",
    "ax1.axhline(2.6, color=\"tab:green\", linestyle=\":\", linewidth=2, label=\"Target val loss\")\n",
    "# ax1.plot([20000, 125000], [3.63, 3.31], color=\"tab:red\", linestyle=\"--\", linewidth=2, label=\"Prev decline\", zorder=99)\n",
    "\n",
    "ax1.legend()\n",
    "ax1.yaxis.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "ax1.xaxis.set_major_locator(mticker.AutoLocator())\n",
    "ax1.xaxis.set_minor_locator(mticker.AutoMinorLocator())\n",
    "ax1.xaxis.grid(True, which=\"both\", linestyle=\":\", linewidth=0.5)\n",
    "# ax1.set_yscale(\"log\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_title(\"Cross Entropy Loss by Step (nats)\")\n",
    "ax1.grid(True)\n",
    "ax1.set_ylim(bottom=1.5, top=4.5)\n",
    "ax1.set_xlim(left=0, right=10)\n",
    "fig1.patch.set_facecolor(\"white\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635644b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Create a figure with GridSpec to control height ratios\n",
    "fig = plt.figure(figsize=(10, 7), facecolor=\"white\")\n",
    "gs = GridSpec(2, 1, height_ratios=[3, 1], hspace=0.15)  # loss taller, lr shorter\n",
    "\n",
    "# --- Loss Plot ---\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "ax1.plot(\n",
    "    df_metrics[\"step\"],\n",
    "    df_metrics[\"train_loss\"],\n",
    "    color=\"tab:blue\",\n",
    "    alpha=0.7,\n",
    "    label=\"Train Loss\",\n",
    ")\n",
    "ax1.plot(\n",
    "    df_metrics[\"step\"][df_metrics[\"val_loss\"].notna()],\n",
    "    df_metrics[\"val_loss\"][df_metrics[\"val_loss\"].notna()],\n",
    "    color=\"tab:orange\",\n",
    "    label=\"Validation Loss\",\n",
    "    zorder=4,\n",
    "    linewidth=3,\n",
    ")\n",
    "ax1.legend()\n",
    "ax1.yaxis.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "ax1.xaxis.set_major_locator(mticker.AutoLocator())\n",
    "ax1.xaxis.set_minor_locator(mticker.AutoMinorLocator())\n",
    "ax1.xaxis.grid(True, which=\"both\", linestyle=\":\", linewidth=0.5)\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_ylim(top=8.0)\n",
    "ax1.set_title(\"Cross Entropy Loss by Step (nats)\")\n",
    "ax1.grid(True)\n",
    "\n",
    "# Remove x-axis labels and ticks for the top plot\n",
    "ax1.set_xlabel(\"\")\n",
    "ax1.tick_params(labelbottom=False)\n",
    "\n",
    "# --- Learning Rate Plot ---\n",
    "ax2 = fig.add_subplot(gs[1], sharex=ax1)\n",
    "ax2.plot(df_metrics[\"step\"], df_metrics[\"muon_lr\"], color=\"tab:green\")\n",
    "ax2.set_xlabel(\"Step\")\n",
    "ax2.set_ylabel(\"Learning Rate\")\n",
    "ax2.grid(True)\n",
    "\n",
    "# Clean layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad97e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the contents\n",
    "with open(\"../../logs/instruct_training_metrics.jsonl\", \"r\") as f:\n",
    "    train_instruct = [json.loads(line) for line in f]\n",
    "\n",
    "df_instruct = pd.DataFrame(train_instruct)\n",
    "df_instruct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
